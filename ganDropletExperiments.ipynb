{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ganDropletExperiments.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5ZbWRr2aXjWB5sFqxR/hY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-quilo/premiereDroplets/blob/main/ganDropletExperiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlrsETHXA54q"
      },
      "source": [
        "Generative adversarial Networks (GANs) for droplet experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R-_Qg8QAwl3"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import tensorflow.keras as tf\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras.backend as backend\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras import backend\n",
        "from keras.layers import Lambda\n",
        "from keras.constraints import Constraint\n",
        "from keras.initializers import RandomNormal\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.utils import np_utils\n",
        "import tensorflow.keras as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH94h3wnJS4i"
      },
      "source": [
        "The new class GANexperiments is defined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWmV1I4YJR6t"
      },
      "source": [
        "class ClipConstraint(Constraint):\n",
        "    # set clip value when initialized\n",
        "    def __init__(self, clip_value):\n",
        "        self.clip_value = clip_value\n",
        "\n",
        "    # clip model weights to hypercube\n",
        "    def __call__(self, weights):\n",
        "        return backend.clip(weights, -self.clip_value, self.clip_value)\n",
        "\n",
        "    # get the config\n",
        "    def get_config(self):\n",
        "        return {'clip_value': self.clip_value}\n",
        "\n",
        "# clip model weights to a given hypercube\n",
        "class AAE():\n",
        "\n",
        "    def __init__(self, directory_data, field_name, npcs, observationPeriod, initNNodes, latent_dim, GANorWGAN):\n",
        "\n",
        "        # Wasserstein loss\n",
        "        def wasserstein_loss(y_true, y_pred):\n",
        "            return backend.mean(y_true * y_pred)\n",
        "\n",
        "        self.field_name = field_name\n",
        "        self.directory_data = directory_data\n",
        "        self.latent_dim = latent_dim\n",
        "        self.npcs = npcs\n",
        "        self.constraint = 0.01\n",
        "        self.dropoutNumber = 0.5\n",
        "        self.alpha = 0.3\n",
        "        self.observationPeriod = observationPeriod\n",
        "        self.initNNodes = initNNodes\n",
        "        self.GANorWGAN = GANorWGAN\n",
        "\n",
        "        self.c1_hist = []\n",
        "        self.c2_hist = []\n",
        "        self.g_hist = []\n",
        "\n",
        "        self.optimizer = tf.optimizers.Nadam()\n",
        "\n",
        "        if self.GANorWGAN == 'WGAN':\n",
        "            self.loss = wasserstein_loss\n",
        "        elif self.GANorWGAN == 'GAN':\n",
        "            self.loss = 'binary_crossentropy'\n",
        "\n",
        "        self.loss_gen = 'mse'\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = self.build_discriminator()\n",
        "\n",
        "        # Build the encoder and decoder\n",
        "        self.generator_encoder = self.build_generator_encoder()\n",
        "        self.generator_decoder = self.build_generator_decoder()\n",
        "\n",
        "        # Only the generator is trained through the combined model, thus:\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # Connecting models\n",
        "        real_input = tf.Input(shape=self.npcs)\n",
        "        encoder_output = self.generator_encoder(real_input)\n",
        "        decoder_output = self.generator_decoder(encoder_output)\n",
        "        discriminator_output = self.discriminator(encoder_output)\n",
        "\n",
        "        # The combined model stacks the autoencoder and discriminator\n",
        "        # The stacked model has one input and two outputs: the decoded input and the discriminator output\n",
        "        self.combined = tf.Model(real_input, [decoder_output, discriminator_output], name = 'AAE')\n",
        "        self.combined.compile(loss=[self.loss_gen, self.loss], loss_weights=[0.999, 0.001], optimizer=self.optimizer)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "        init = RandomNormal(stddev=0.02)\n",
        "        const = ClipConstraint(0.01)\n",
        "\n",
        "        in_disc = tf.Input(shape=(self.latent_dim))\n",
        "        disc = tf.layers.LeakyReLU(self.alpha)(in_disc)\n",
        "        disc = tf.layers.BatchNormalization()(disc)\n",
        "        disc_output = tf.layers.Dense(1, activation='sigmoid')(disc)\n",
        "        discriminator = tf.Model(in_disc, disc_output, name='Discriminator')\n",
        "        discriminator.compile(loss=self.loss, optimizer=self.optimizer)\n",
        "\n",
        "        return discriminator\n",
        "\n",
        "    def build_generator_encoder(self):\n",
        "        init = RandomNormal(stddev=0.02)\n",
        "        init = tf.initializers.RandomNormal(stddev=0.02)\n",
        "\n",
        "        input_enc = tf.Input(shape=self.npcs)\n",
        "        nNodes = self.initNNodes\n",
        "        flag = 0\n",
        "        while nNodes > latent_dim:\n",
        "            if flag == 0:\n",
        "                enc = tf.layers.Dense(nNodes)(input_enc)\n",
        "                flag = 1\n",
        "            else:\n",
        "                enc = tf.layers.Dense(nNodes)(enc)\n",
        "            enc = tf.layers.LeakyReLU(self.alpha)(enc)\n",
        "            enc = tf.layers.BatchNormalization()(enc)\n",
        "            nNodes = nNodes / 2\n",
        "        mu = tf.layers.Dense(latent_dim)(enc)\n",
        "        sigma = tf.layers.Dense(latent_dim)(enc)\n",
        "\n",
        "        # The latent representation (\"fake\") in a Gaussian distribution is then compared to the \"real\" arbitrary Gaussian\n",
        "        # distribution fed in the Discriminator\n",
        "        latent_repr = tf.layers.Lambda(\n",
        "            lambda p: p[0] + backend.random_normal(backend.shape(p[0])) * backend.exp(p[1] / 2))(\n",
        "            [mu, sigma])\n",
        "        generator_encoder = tf.Model(input_enc, latent_repr, name='Encoder')\n",
        "        generator_encoder.summary()\n",
        "        return generator_encoder\n",
        "\n",
        "    def build_generator_decoder(self):\n",
        "        init = RandomNormal(stddev=0.02)\n",
        "        init = tf.initializers.RandomNormal(stddev=0.02)\n",
        "\n",
        "        # Input to the decoder is the latent space from the encoder\n",
        "        input_dec = tf.Input(shape=self.latent_dim)\n",
        "        n = 2 * latent_dim\n",
        "        flag = 0\n",
        "        while n <= self.initNNodes:\n",
        "            if flag == 0:\n",
        "                dec = tf.layers.Dense(n)(input_dec)\n",
        "                flag = 1\n",
        "            else:\n",
        "                dec = tf.layers.Dense(n)(dec)\n",
        "            dec = tf.layers.LeakyReLU(self.alpha)(dec)\n",
        "            dec = tf.layers.BatchNormalization()(dec)\n",
        "            n = n * 2\n",
        "        output_dec = tf.layers.Dense(self.npcs, activation='tanh')(dec)\n",
        "        generator_decoder = tf.Model(input_dec, output_dec, name='Decoder')\n",
        "\n",
        "        generator_decoder.summary()\n",
        "        return generator_decoder\n",
        "\n",
        "\n",
        "    def train(self, epochs, batch_size=128, sample_interval=50, n_critic=5):\n",
        "\n",
        "        # Load and pre process the data\n",
        "\n",
        "        pcs_trun = np.load(self.directory_data + '/' + 'pcs_' + self.field_name + '_' +\n",
        "                           self.observationPeriod + '.npy')\n",
        "\n",
        "        np.random.seed(42)\n",
        "\n",
        "        min_ls = np.min(pcs_trun)\n",
        "        max_ls = np.max(pcs_trun)\n",
        "        min = -1\n",
        "        max = +1\n",
        "\n",
        "        def scaler(x, xmin, xmax, min, max):\n",
        "            scale = (max - min) / (xmax - xmin)\n",
        "            xScaled = scale * x + min - xmin * scale\n",
        "            return xScaled\n",
        "\n",
        "        ls_scaled = scaler(pcs_trun, min_ls, max_ls, min, max)\n",
        "\n",
        "        global X_train, y_train, X_all\n",
        "\n",
        "        X_all = ls_scaled\n",
        "\n",
        "        if self.GANorWGAN == 'WGAN':\n",
        "            real = -np.ones(batch_size)\n",
        "            fake = np.ones(batch_size)\n",
        "\n",
        "        if self.GANorWGAN == 'GAN':\n",
        "            real = np.ones(batch_size)\n",
        "            fake = np.zeros(batch_size)\n",
        "\n",
        "        # Training the model\n",
        "        for epoch in range(epochs):\n",
        "            c1_tmp, c2_tmp = list(), list()\n",
        "\n",
        "            # Training the discriminator more often than the generator\n",
        "            for _ in range(n_critic):\n",
        "                # Randomly selected samples and noise\n",
        "                randomIndex = np.random.randint(0, X_all.shape[0], size=batch_size)\n",
        "                noise = np.random.normal(0, 1, size=(batch_size, self.latent_dim))\n",
        "                # Select a random batch of input\n",
        "                real_seqs = X_all[randomIndex]\n",
        "\n",
        "                # Generate a batch of new outputs (in the latent space) predicted by the encoder\n",
        "                gen_seqs = self.generator_encoder.predict(real_seqs)\n",
        "\n",
        "                # Train the discriminator\n",
        "                # The arbitrary noise is considered to be a \"real\" sample\n",
        "                d_loss_real = self.discriminator.train_on_batch(noise, real)\n",
        "                c1_tmp.append(d_loss_real)\n",
        "                # The latent space generated by the encoder is considered a \"fake\" sample\n",
        "                d_loss_fake = self.discriminator.train_on_batch(gen_seqs, fake)\n",
        "                c2_tmp.append(d_loss_fake)\n",
        "\n",
        "            self.c1_hist.append(np.mean(c1_tmp))\n",
        "            self.c2_hist.append(np.mean(c2_tmp))\n",
        "\n",
        "            # Training the stacked model\n",
        "            g_loss = self.combined.train_on_batch(real_seqs, [real_seqs, real])\n",
        "            self.g_hist.append(g_loss)\n",
        "            print(\"%d [C1 real: %f, C2 fake: %f], [G loss: %f, mse: %f]\" % (epoch, self.c1_hist[epoch], self.c2_hist[epoch], g_loss[0], g_loss[1]))\n",
        "\n",
        "            # Checkpoint progress: Plot losses and predicted data\n",
        "            if epoch % sample_interval == 0:\n",
        "\n",
        "                self.plot_loss(epoch)\n",
        "                self.plot_values(epoch)\n",
        "                self.generator_encoder.save(self.directory_data + '/' + 'AAE_MV_generator_encoder_Full_' + GANorWGAN +\n",
        "                                            '_' + self.field_name + '_' + str(self.latent_dim) + '_' + str(epoch),\n",
        "                                            save_format='tf')\n",
        "                self.generator_decoder.save(self.directory_data + '/' + 'AAE_MV_generator_decoder_Full_' + GANorWGAN +\n",
        "                                            '_' + self.field_name + '_' + str(self.latent_dim) + '_' + str(epoch),\n",
        "                                            save_format='tf')\n",
        "\n",
        "                self.discriminator.save(self.directory_data + '/' + 'AAE_MV_discriminator_Full_WGAN_' + GANorWGAN +\n",
        "                                        '_' + self.field_name + '_' + str(self.latent_dim) + '_' + str(epoch),\n",
        "                                        save_format='tf')\n",
        "\n",
        "    # Plots the (W)GAN related losses at every sample interval\n",
        "\n",
        "    def plot_loss(self, epoch):\n",
        "        fig = plt.figure()\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.plot(self.c1_hist, c='red')\n",
        "        plt.plot(self.c2_hist, c='blue')\n",
        "        plt.plot(self.g_hist[0][0], c='orange')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(\"GAN Loss per Epoch\")\n",
        "        plt.legend(['C real', 'C fake', 'Generator'])\n",
        "\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.plot(self.g_hist[0][1], c='green')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Mean squared error')\n",
        "        plt.title('MSE loss')\n",
        "        plt.savefig(self.directory_data + '/' + 'Losses_AAE_MV-PCAE_' + GANorWGAN + '_' + self.field_name + '_' + '_' + str(epoch) +\n",
        "                    '_' + str(self.latent_dim) + '.png')\n",
        "        plt.close()\n",
        "\n",
        "    # Plots predicted in the first 8 latent dimension at every sample interval\n",
        "\n",
        "    def plot_values(self, epoch):\n",
        "\n",
        "        prediction = self.generator_decoder.predict(self.generator_encoder(X_all))\n",
        "        for i in np.arange(12):\n",
        "            plt.subplot(3, 4, i+1)\n",
        "            plt.plot(X_all[:, i])\n",
        "            plt.plot(prediction[:, i], alpha=0.8)\n",
        "\n",
        "            #plt.legend(['Prediction', 'GT'])\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(self.directory_data + '/' + 'Plots_AAE_MV-PCAE_' + GANorWGAN + '_' + self.field_name + '_' + '_' + str(epoch) +\n",
        "                    '_' + str(self.latent_dim) + '.png')\n",
        "        plt.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    directory_data = '/Users/cequilod/sLSBU_Simulation/data_150_to_1150'\n",
        "    field_name = 'Velocity'\n",
        "\n",
        "    epochs = 100001\n",
        "    batch_size = 32\n",
        "    n_critic = 5\n",
        "    sample_interval = 10000\n",
        "    latent_dim = 4\n",
        "    npcs = 1000\n",
        "    #Interval within the simulation\n",
        "    start = 150\n",
        "    end = 1150\n",
        "    observationPeriod = 'data_' + str(start) + '_to_' + str(end)\n",
        "    #Initial number of nodes for the AE\n",
        "    initNNodes = 64\n",
        "    #Training method\n",
        "    GANorWGAN = 'WGAN'\n",
        "    advAE = AAE(directory_data=directory_data,\n",
        "              field_name=field_name,\n",
        "              npcs=npcs,\n",
        "              observationPeriod=observationPeriod,\n",
        "              initNNodes=initNNodes,\n",
        "              latent_dim=latent_dim,\n",
        "              GANorWGAN=GANorWGAN)\n",
        "\n",
        "    advAE.train(epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              sample_interval=sample_interval,\n",
        "              n_critic = n_critic)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}